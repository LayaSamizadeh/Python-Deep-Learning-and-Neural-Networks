{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exmple data:\n",
    " - experimental drug was tested on individuals ranging from age 13 to 100 in a clinical trial.\n",
    " - The trial had 2100 participants. Half of the participants were under 65 years old, and the other half was 65 years of age or older.\n",
    " - around 95% of patients 65 or older experienced side effects from the drug\n",
    " - around 95% of patients under 65 experienced no side effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    # The ~5% of younger individuals who did exprience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "\n",
    "    # The ~5% of older individuals who did not exprience side effects\n",
    "    random_older = randint(64,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "\n",
    "for i in range(1000):\n",
    "    # The ~95% of younger individuals who did not exprience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "\n",
    "    # The ~95% of older individuals who did exprience side effects\n",
    "    random_older = randint(64,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "[52, 73, 28, 67, 64, 83, 59, 75, 20, 93, 24, 92, 28, 98, 15, 99, 56, 84, 27, 78, 19, 75, 15, 74, 24, 78, 54, 92, 63, 86, 54, 89, 22, 71, 53, 70, 48, 99, 52, 85, 25, 72, 62, 73, 52, 95, 42, 96, 44, 64, 38, 76, 62, 68, 41, 69, 50, 97, 16, 74, 30, 77, 50, 91, 24, 77, 29, 79, 13, 96, 55, 74, 50, 79, 56, 73, 50, 88, 18, 95, 26, 84, 28, 73, 62, 67, 24, 68, 47, 68, 16, 81, 35, 75, 49, 64, 64, 82, 46, 98, 60, 92, 56, 78, 23, 82, 40, 83, 49, 72, 51, 71, 54, 91, 25, 74, 62, 97, 40, 73, 37, 68, 62, 89, 32, 97, 64, 80, 20, 93, 36, 86, 20, 88, 63, 95, 42, 72, 20, 68, 41, 74, 61, 84, 21, 78, 25, 83, 33, 99, 28, 68, 24, 77, 28, 74, 64, 97, 32, 86, 30, 72, 22, 95, 55, 76, 15, 70, 28, 100, 17, 84, 61, 68, 20, 72, 43, 66, 61, 79, 44, 71, 16, 100, 13, 70, 14, 71, 46, 79, 21, 89, 57, 76, 45, 71, 43, 97, 56, 74, 57, 88, 46, 64, 60, 75, 63, 92, 61, 99, 14, 94, 40, 64, 56, 67, 54, 71, 15, 66, 29, 68, 52, 80, 39, 88, 35, 97, 58, 87, 53, 99, 14, 96, 18, 88, 43, 74, 49, 74, 33, 86, 49, 88, 31, 79, 40, 99, 26, 78, 63, 70, 21, 74, 61, 65, 61, 70, 44, 86, 34, 72, 21, 72, 35, 100, 58, 71, 57, 80, 17, 98, 59, 85, 31, 70, 63, 74, 44, 72, 16, 83, 15, 94, 33, 69, 45, 65, 45, 98, 16, 72, 30, 94, 21, 66, 50, 70, 60, 64, 17, 78, 64, 73, 16, 98, 48, 80, 58, 71, 30, 77, 35, 95, 36, 68, 28, 86, 20, 97, 47, 98, 26, 75, 43, 65, 58, 72, 50, 74, 44, 95, 62, 78, 14, 81, 24, 91, 32, 88, 47, 85, 20, 85, 60, 97, 22, 66, 46, 97, 62, 100, 36, 73, 60, 72, 14, 65, 51, 77, 63, 70, 27, 96, 17, 69, 19, 82, 23, 89, 31, 76, 53, 92, 51, 64, 14, 94, 47, 67, 19, 100, 30, 68, 49, 97, 41, 93, 57, 72, 50, 73, 53, 94, 21, 78, 62, 96, 34, 74, 21, 86, 45, 67, 41, 84, 22, 65, 18, 74, 23, 69, 22, 80, 38, 72, 28, 100, 27, 100, 29, 99, 18, 68, 32, 69, 55, 82, 44, 97, 19, 90, 13, 91, 42, 90, 34, 90, 63, 92, 51, 89, 52, 73, 63, 69, 36, 94, 51, 85, 60, 79, 47, 90, 52, 87, 22, 100, 62, 67, 42, 74, 46, 83, 23, 66, 55, 81, 57, 71, 19, 81, 49, 98, 23, 90, 55, 83, 49, 90, 14, 93, 16, 78, 42, 80, 24, 83, 20, 66, 56, 87, 42, 81, 63, 73, 22, 85, 59, 89, 28, 82, 33, 85, 24, 73, 28, 90, 58, 88, 19, 67, 22, 68, 64, 92, 45, 100, 45, 86, 30, 89, 26, 77, 30, 82, 27, 80, 18, 69, 50, 88, 22, 88, 62, 96, 16, 86, 35, 71, 47, 91, 44, 82, 30, 86, 35, 89, 25, 100, 59, 70, 34, 64, 47, 96, 60, 85, 18, 71, 23, 70, 21, 95, 20, 83, 19, 82, 61, 75, 57, 71, 21, 89, 30, 64, 61, 79, 51, 90, 42, 79, 33, 96, 21, 92, 26, 65, 59, 93, 20, 66, 31, 90, 36, 76, 46, 83, 58, 75, 42, 82, 40, 93, 19, 78, 41, 72, 30, 100, 55, 70, 45, 93, 60, 99, 53, 64, 54, 73, 46, 69, 42, 95, 27, 70, 38, 87, 26, 68, 26, 82, 35, 67, 57, 86, 64, 85, 43, 70, 59, 85, 50, 69, 27, 64, 33, 100, 31, 98, 49, 81, 61, 76, 55, 95, 47, 88, 31, 66, 45, 96, 43, 76, 14, 86, 61, 71, 20, 84, 33, 99, 18, 88, 29, 84, 37, 95, 49, 94, 60, 73, 30, 79, 56, 85, 55, 88, 21, 64, 19, 100, 27, 79, 39, 66, 16, 71, 39, 71, 23, 85, 58, 78, 62, 71, 13, 89, 21, 64, 59, 64, 21, 87, 22, 83, 58, 75, 62, 82, 17, 72, 24, 86, 64, 92, 33, 86, 62, 79, 25, 85, 31, 93, 42, 69, 50, 73, 24, 64, 39, 71, 16, 76, 54, 78, 52, 70, 52, 65, 59, 90, 56, 78, 35, 72, 35, 80, 21, 81, 41, 100, 63, 83, 39, 86, 22, 67, 64, 96, 53, 65, 61, 78, 32, 68, 59, 100, 46, 86, 49, 95, 62, 95, 64, 87, 49, 83, 46, 82, 56, 77, 56, 80, 50, 80, 44, 96, 59, 66, 62, 88, 62, 65, 62, 74, 19, 72, 47, 87, 29, 69, 29, 67, 27, 80, 50, 75, 15, 100, 17, 91, 60, 87, 15, 82, 30, 97, 37, 77, 43, 68, 47, 98, 27, 70, 40, 98, 37, 90, 13, 66, 58, 94, 30, 78, 26, 76, 14, 81, 61, 66, 46, 76, 41, 90, 43, 67, 31, 64, 37, 93, 48, 92, 45, 85, 51, 70, 28, 65, 14, 96, 24, 70, 63, 94, 41, 100, 39, 80, 48, 69, 17, 92, 13, 100, 13, 75, 49, 100, 37, 83, 51, 96, 30, 75, 17, 75, 33, 93, 13, 76, 19, 70, 51, 88, 64, 93, 19, 96, 63, 97, 17, 96, 55, 67, 61, 80, 47, 80, 43, 89, 47, 86, 33, 82, 13, 72, 47, 94, 33, 71, 14, 95, 26, 83, 49, 92, 38, 100, 42, 93, 34, 81, 57, 80, 41, 85, 42, 72, 20, 86, 24, 83, 30, 64, 61, 77, 51, 91, 55, 66, 25, 99, 32, 74, 22, 94, 56, 67, 48, 89, 19, 93, 33, 69, 49, 91, 16, 98, 33, 81, 54, 97, 48, 81, 29, 81, 57, 74, 35, 92, 62, 98, 48, 84, 18, 94, 58, 100, 50, 78, 43, 65, 39, 91, 33, 70, 55, 91, 24, 74, 59, 90, 55, 92, 56, 98, 49, 93, 44, 65, 45, 90, 26, 95, 15, 81, 45, 90, 41, 96, 19, 86, 51, 99, 39, 90, 59, 77, 24, 88, 55, 96, 29, 92, 22, 99, 60, 81, 33, 82, 45, 70, 16, 84, 17, 64, 56, 91, 49, 68, 26, 88, 34, 65, 23, 90, 14, 75, 18, 78, 23, 97, 51, 75, 42, 79, 59, 87, 16, 100, 26, 92, 47, 81, 61, 77, 42, 68, 16, 79, 18, 89, 46, 68, 47, 70, 44, 73, 28, 70, 24, 80, 15, 82, 40, 80, 26, 66, 25, 94, 14, 64, 57, 93, 57, 99, 62, 100, 17, 83, 58, 99, 34, 71, 42, 87, 60, 80, 38, 83, 17, 77, 40, 74, 64, 71, 41, 67, 49, 83, 62, 74, 59, 65, 45, 95, 31, 100, 13, 69, 21, 68, 20, 93, 58, 80, 42, 93, 50, 81, 40, 89, 37, 69, 35, 76, 40, 86, 24, 76, 42, 89, 19, 68, 41, 65, 20, 90, 38, 87, 62, 69, 48, 90, 48, 84, 14, 98, 33, 93, 45, 97, 18, 79, 55, 90, 21, 78, 30, 82, 18, 78, 46, 92, 27, 80, 27, 80, 28, 92, 61, 96, 18, 98, 62, 82, 52, 98, 30, 96, 51, 77, 51, 97, 28, 93, 44, 86, 16, 77, 42, 76, 46, 81, 16, 77, 34, 94, 42, 95, 18, 82, 33, 64, 63, 92, 28, 79, 17, 94, 49, 94, 55, 78, 36, 86, 51, 68, 30, 92, 42, 89, 60, 84, 17, 97, 40, 94, 16, 80, 62, 79, 23, 87, 56, 90, 26, 71, 59, 70, 27, 83, 46, 66, 58, 98, 17, 92, 59, 74, 57, 88, 36, 65, 55, 96, 25, 93, 46, 76, 16, 78, 58, 65, 41, 76, 44, 87, 59, 81, 43, 79, 37, 87, 24, 92, 21, 100, 63, 97, 53, 83, 58, 88, 45, 99, 64, 72, 23, 83, 46, 93, 46, 94, 39, 89, 46, 90, 19, 85, 49, 88, 44, 95, 17, 88, 25, 100, 17, 85, 33, 68, 25, 67, 50, 72, 41, 83, 15, 66, 51, 72, 49, 89, 20, 79, 23, 85, 23, 96, 56, 79, 41, 81, 61, 75, 49, 74, 48, 79, 37, 81, 40, 89, 32, 68, 14, 91, 48, 82, 38, 87, 57, 89, 22, 71, 56, 77, 21, 72, 19, 85, 32, 74, 56, 98, 46, 95, 55, 66, 18, 86, 18, 78, 58, 85, 38, 76, 24, 100, 62, 87, 23, 64, 13, 77, 38, 89, 34, 90, 15, 93, 17, 99, 41, 68, 42, 81, 43, 72, 48, 81, 61, 75, 40, 71, 63, 88, 31, 97, 40, 90, 49, 99, 23, 78, 32, 93, 29, 69, 14, 86, 34, 68, 27, 69, 14, 91, 20, 82, 58, 78, 19, 97, 22, 72, 22, 94, 30, 87, 23, 90, 47, 86, 26, 70, 54, 80, 33, 72, 44, 95, 51, 65, 23, 72, 44, 94, 16, 68, 24, 78, 46, 89, 54, 67, 21, 95, 30, 70, 52, 92, 50, 78, 50, 79, 13, 98, 25, 79, 22, 84, 47, 73, 54, 87, 26, 76, 47, 68, 43, 68, 37, 81, 43, 100, 24, 91, 33, 69, 51, 79, 57, 71, 53, 87, 54, 64, 54, 95, 23, 64, 26, 99, 18, 93, 30, 70, 55, 74, 37, 100, 25, 66, 55, 67, 53, 65, 24, 99, 37, 76, 27, 97, 59, 66, 14, 74, 32, 89, 39, 75, 35, 74, 31, 89, 31, 83, 29, 89, 44, 99, 36, 85, 17, 67, 43, 71, 32, 99, 24, 72, 25, 92, 35, 88, 13, 100, 51, 88, 28, 86, 56, 95, 30, 84, 31, 66, 60, 84, 22, 86, 21, 91, 35, 76, 48, 64, 35, 79, 26, 85, 57, 80, 24, 77, 56, 87, 23, 71, 50, 85, 45, 89, 41, 89, 39, 98, 14, 79, 43, 84, 40, 82, 59, 97, 53, 65, 21, 76, 41, 80, 47, 90, 46, 92, 33, 67, 35, 66, 30, 88, 56, 86, 25, 66, 20, 92, 45, 76, 41, 65, 19, 68, 46, 82, 18, 64, 25, 89, 42, 96, 41, 79, 33, 90, 50, 97, 50, 78, 34, 64, 56, 86, 44, 92, 13, 65, 58, 81, 60, 83, 48, 96, 30, 79, 17, 99, 28, 97, 27, 88, 15, 100, 48, 73, 51, 81, 59, 86, 41, 65, 14, 88, 54, 79, 47, 79, 47, 92, 35, 87, 51, 98, 38, 76, 25, 97, 18, 86, 53, 72, 23, 75, 41, 90, 19, 76, 35, 93, 44, 91, 47, 100, 19, 88, 39, 72, 58, 65, 48, 68, 28, 83, 59, 79, 29, 64, 19, 72, 33, 97, 59, 89, 46, 90, 36, 71, 56, 87, 45, 79, 29, 80, 30, 95, 41, 90, 60, 81, 42, 76, 46, 83, 55, 92, 17, 81, 32, 91, 53, 100, 13, 91, 44, 93, 50, 88, 23, 78, 48, 81, 18, 94, 55, 95, 57, 96, 13, 96, 19, 81, 41, 96, 34, 99, 18, 67, 19, 84, 15, 76, 41, 82, 28, 66, 59, 82, 36, 96, 27, 93, 47, 95, 43, 89, 47, 99, 51, 69, 15, 93, 38, 93, 21, 87, 19, 89, 40, 88, 57, 94, 15, 99, 49, 98, 29, 76, 34, 65, 49, 88, 24, 80, 54, 100, 15, 99, 30, 79, 51, 89, 35, 77, 19, 98, 53, 100, 14, 74, 22, 85, 64, 88, 54, 69, 57, 72, 37, 64, 59, 95, 27, 79, 50, 86, 53, 95, 46, 67, 46, 96, 46, 70, 41, 65, 52, 69, 58, 78, 17, 79, 51, 77, 55, 99, 36, 82, 48, 95, 55, 96, 59, 87, 14, 81, 17, 92, 40, 71, 28, 83, 41, 79, 60, 91, 47, 80, 16, 74, 14, 68, 44, 90, 17, 90, 17, 92, 53, 75, 45, 69, 48, 98, 30, 67, 38, 90, 56, 89, 57, 93, 17, 73, 36, 73, 30, 73, 17, 83, 56, 97, 20, 69, 27, 94, 39, 95, 31, 70, 43, 84, 61, 74, 32, 89, 51, 75, 22, 84, 14, 64, 50, 83, 63, 82, 16, 77, 36, 100, 41, 80, 26, 84, 60, 81, 64, 75, 19, 83, 20, 88, 36, 75, 44, 84, 43, 80, 29, 100, 42, 64, 29, 95, 58, 91, 32, 100, 56, 96, 34, 91, 34, 69, 50, 64, 61, 72, 52, 64, 28, 66, 13, 74, 24, 87, 35, 81, 43, 69, 52, 96, 40, 66, 34, 91, 50, 67, 27, 88, 60, 71, 59, 73, 61, 89, 47, 72, 40, 78, 33, 70, 17, 78, 43, 91, 13, 98]\n"
     ]
    }
   ],
   "source": [
    "print (train_labels) \n",
    "print (train_samples) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert both lists into numpy arrays due to what the fit() function expects, and then shuffle the arrays to remove any order that was imposed on the data during the creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels , train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1]\n",
      "[99 80 76 65 87 29 94 79 20 27 83 33 66 96 47 40 52 85 19 30 73 73 67 18\n",
      " 65]\n"
     ]
    }
   ],
   "source": [
    "print (train_labels[:25]) \n",
    "print (train_samples[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98850575]\n",
      " [0.77011494]\n",
      " [0.72413793]\n",
      " [0.59770115]\n",
      " [0.85057471]\n",
      " [0.18390805]\n",
      " [0.93103448]\n",
      " [0.75862069]\n",
      " [0.08045977]\n",
      " [0.16091954]]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_train_samples[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple tf,tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\Desktop\\Music AI\\Python-Deep-Learning-and-Neural-Networks\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 16)                32        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 642 (2.51 KB)\n",
      "Trainable params: 642 (2.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\Desktop\\Music AI\\Python-Deep-Learning-and-Neural-Networks\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\Desktop\\Music AI\\Python-Deep-Learning-and-Neural-Networks\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "210/210 - 1s - loss: 0.6633 - accuracy: 0.5333 - 750ms/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "210/210 - 0s - loss: 0.6315 - accuracy: 0.6638 - 158ms/epoch - 753us/step\n",
      "Epoch 3/30\n",
      "210/210 - 0s - loss: 0.5943 - accuracy: 0.7367 - 150ms/epoch - 715us/step\n",
      "Epoch 4/30\n",
      "210/210 - 0s - loss: 0.5572 - accuracy: 0.7829 - 164ms/epoch - 783us/step\n",
      "Epoch 5/30\n",
      "210/210 - 0s - loss: 0.5208 - accuracy: 0.8129 - 154ms/epoch - 733us/step\n",
      "Epoch 6/30\n",
      "210/210 - 0s - loss: 0.4837 - accuracy: 0.8452 - 155ms/epoch - 740us/step\n",
      "Epoch 7/30\n",
      "210/210 - 0s - loss: 0.4507 - accuracy: 0.8619 - 153ms/epoch - 730us/step\n",
      "Epoch 8/30\n",
      "210/210 - 0s - loss: 0.4213 - accuracy: 0.8681 - 162ms/epoch - 772us/step\n",
      "Epoch 9/30\n",
      "210/210 - 0s - loss: 0.3950 - accuracy: 0.8857 - 160ms/epoch - 761us/step\n",
      "Epoch 10/30\n",
      "210/210 - 0s - loss: 0.3723 - accuracy: 0.8924 - 155ms/epoch - 739us/step\n",
      "Epoch 11/30\n",
      "210/210 - 0s - loss: 0.3527 - accuracy: 0.9043 - 155ms/epoch - 740us/step\n",
      "Epoch 12/30\n",
      "210/210 - 0s - loss: 0.3364 - accuracy: 0.9129 - 163ms/epoch - 778us/step\n",
      "Epoch 13/30\n",
      "210/210 - 0s - loss: 0.3228 - accuracy: 0.9195 - 161ms/epoch - 766us/step\n",
      "Epoch 14/30\n",
      "210/210 - 0s - loss: 0.3115 - accuracy: 0.9162 - 162ms/epoch - 771us/step\n",
      "Epoch 15/30\n",
      "210/210 - 0s - loss: 0.3022 - accuracy: 0.9271 - 162ms/epoch - 770us/step\n",
      "Epoch 16/30\n",
      "210/210 - 0s - loss: 0.2944 - accuracy: 0.9233 - 158ms/epoch - 754us/step\n",
      "Epoch 17/30\n",
      "210/210 - 0s - loss: 0.2879 - accuracy: 0.9319 - 150ms/epoch - 714us/step\n",
      "Epoch 18/30\n",
      "210/210 - 0s - loss: 0.2827 - accuracy: 0.9310 - 154ms/epoch - 733us/step\n",
      "Epoch 19/30\n",
      "210/210 - 0s - loss: 0.2780 - accuracy: 0.9329 - 154ms/epoch - 733us/step\n",
      "Epoch 20/30\n",
      "210/210 - 0s - loss: 0.2740 - accuracy: 0.9324 - 151ms/epoch - 721us/step\n",
      "Epoch 21/30\n",
      "210/210 - 0s - loss: 0.2706 - accuracy: 0.9400 - 155ms/epoch - 739us/step\n",
      "Epoch 22/30\n",
      "210/210 - 0s - loss: 0.2678 - accuracy: 0.9333 - 156ms/epoch - 742us/step\n",
      "Epoch 23/30\n",
      "210/210 - 0s - loss: 0.2654 - accuracy: 0.9371 - 162ms/epoch - 771us/step\n",
      "Epoch 24/30\n",
      "210/210 - 0s - loss: 0.2633 - accuracy: 0.9376 - 157ms/epoch - 747us/step\n",
      "Epoch 25/30\n",
      "210/210 - 0s - loss: 0.2613 - accuracy: 0.9400 - 154ms/epoch - 733us/step\n",
      "Epoch 26/30\n",
      "210/210 - 0s - loss: 0.2596 - accuracy: 0.9410 - 153ms/epoch - 727us/step\n",
      "Epoch 27/30\n",
      "210/210 - 0s - loss: 0.2582 - accuracy: 0.9405 - 154ms/epoch - 732us/step\n",
      "Epoch 28/30\n",
      "210/210 - 0s - loss: 0.2568 - accuracy: 0.9405 - 160ms/epoch - 761us/step\n",
      "Epoch 29/30\n",
      "210/210 - 0s - loss: 0.2556 - accuracy: 0.9419 - 152ms/epoch - 722us/step\n",
      "Epoch 30/30\n",
      "210/210 - 0s - loss: 0.2544 - accuracy: 0.9371 - 151ms/epoch - 720us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x13918d22510>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
